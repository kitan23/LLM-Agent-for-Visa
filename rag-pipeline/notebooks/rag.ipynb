{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (0.3.24)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.55 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain) (0.3.55)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain) (0.3.8)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain) (0.3.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain) (2.11.3)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain) (2.0.40)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain) (6.0.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (24.2)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain-core<1.0.0,>=0.3.55->langchain) (4.13.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests<3,>=2->langchain) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests<3,>=2->langchain) (2025.1.31)\n",
      "Requirement already satisfied: anyio in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.55->langchain) (3.0.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: torch in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (2.7.0)\n",
      "Requirement already satisfied: torchvision in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (0.22.0)\n",
      "Requirement already satisfied: filelock in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch) (79.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: numpy in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torchvision) (2.2.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torchvision) (11.2.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from jinja2->torch) (3.0.2)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: sentence-transformers in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (4.1.0)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.41.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sentence-transformers) (4.51.3)\n",
      "Requirement already satisfied: tqdm in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sentence-transformers) (4.67.1)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sentence-transformers) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sentence-transformers) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sentence-transformers) (1.15.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.20.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sentence-transformers) (0.30.2)\n",
      "Requirement already satisfied: Pillow in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sentence-transformers) (11.2.1)\n",
      "Requirement already satisfied: typing_extensions>=4.5.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sentence-transformers) (4.13.2)\n",
      "Requirement already satisfied: filelock in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.20.0->sentence-transformers) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (79.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers) (3.1.6)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2.2.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (2024.11.6)\n",
      "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.21.1)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from transformers<5.0.0,>=4.41.0->sentence-transformers) (0.5.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from scikit-learn->sentence-transformers) (3.6.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests->huggingface-hub>=0.20.0->sentence-transformers) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: accelerate in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (1.6.0)\n",
      "Requirement already satisfied: numpy<3.0.0,>=1.17 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from accelerate) (2.2.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from accelerate) (24.2)\n",
      "Requirement already satisfied: psutil in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from accelerate) (7.0.0)\n",
      "Requirement already satisfied: pyyaml in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from accelerate) (6.0.2)\n",
      "Requirement already satisfied: torch>=2.0.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from accelerate) (2.7.0)\n",
      "Requirement already satisfied: huggingface-hub>=0.21.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from accelerate) (0.30.2)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from accelerate) (0.5.3)\n",
      "Requirement already satisfied: filelock in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate) (2025.3.2)\n",
      "Requirement already satisfied: requests in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.21.0->accelerate) (4.13.2)\n",
      "Requirement already satisfied: setuptools in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (79.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch>=2.0.0->accelerate) (3.1.6)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Requirement already satisfied: langchain_huggingface in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (0.1.2)\n",
      "Requirement already satisfied: huggingface-hub>=0.23.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain_huggingface) (0.30.2)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.15 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain_huggingface) (0.3.55)\n",
      "Requirement already satisfied: sentence-transformers>=2.6.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain_huggingface) (4.1.0)\n",
      "Requirement already satisfied: tokenizers>=0.19.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain_huggingface) (0.21.1)\n",
      "Requirement already satisfied: transformers>=4.39.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain_huggingface) (4.51.3)\n",
      "Requirement already satisfied: filelock in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (3.18.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2025.3.2)\n",
      "Requirement already satisfied: packaging>=20.9 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.2)\n",
      "Requirement already satisfied: requests in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.13.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.3.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (9.1.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.11.3)\n",
      "Requirement already satisfied: torch>=1.11.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (2.7.0)\n",
      "Requirement already satisfied: scikit-learn in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.6.1)\n",
      "Requirement already satisfied: scipy in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.15.2)\n",
      "Requirement already satisfied: Pillow in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (11.2.1)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from transformers>=4.39.0->langchain_huggingface) (2.2.5)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.11.6)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from transformers>=4.39.0->langchain_huggingface) (0.5.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.28.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from pydantic<3.0.0,>=2.7.4->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.4.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2025.1.31)\n",
      "Requirement already satisfied: setuptools in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (79.0.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.13.3)\n",
      "Requirement already satisfied: networkx in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.1.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (3.6.0)\n",
      "Requirement already satisfied: anyio in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (4.9.0)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.0.8)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (0.14.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from sympy>=1.13.3->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface) (3.0.2)\n",
      "Requirement already satisfied: sniffio>=1.1 in /Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.15->langchain_huggingface) (1.3.1)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain\n",
    "%pip install -qU langchain-community faiss-cpu\n",
    "\n",
    "\n",
    "%pip install torch torchvision\n",
    "%pip install -U sentence-transformers\n",
    "%pip install accelerate\n",
    "%pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --quiet --upgrade langchain-text-splitters langchain-community langgraph\n",
    "\n",
    "%pip install -qU langchain_ollama\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.3.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.0.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install -qU langchain_ollama\n",
    "%pip install -qU pypdf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MPS is available\n",
      "Using mps for hardware acceleration\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "\n",
    "# For those with NVIDIA graphics card\n",
    "torch.cuda.is_available()\n",
    "\n",
    "# Apple alternative \n",
    "torch.backends.mps.is_available()\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available\")\n",
    "    hardware = \"cuda\"\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "    print(\"MPS is available\")\n",
    "    hardware = \"mps\"\n",
    "\n",
    "print(f\"Using {hardware} for hardware acceleration\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The capital of Vietnam is Hanoi.\n"
     ]
    }
   ],
   "source": [
    "from langchain_ollama import OllamaLLM\n",
    "\n",
    "llm = OllamaLLM(model=\"qwen2.5:1.5b\")\n",
    "\n",
    "response = llm.invoke(\"What is the capital of Vietnam?\")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of chunks:  125\n",
      "<class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader, PyPDFDirectoryLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "\n",
    "# files = [\"berkeley_opt.pdf\", \"uscis_opt.pdf\"]\n",
    "loader = PyPDFDirectoryLoader(\"../examples\")\n",
    "pages = []\n",
    "async for page in loader.alazy_load():\n",
    "    pages.append(page)\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=1000, # 1000 characters per chunk\n",
    "    chunk_overlap=200 # 200 characters overlap between chunks\n",
    ")\n",
    "\n",
    "chunks = []\n",
    "\n",
    "for page in pages:\n",
    "    chunk_list = text_splitter.split_text(page.page_content)\n",
    "    for chunk in chunk_list:\n",
    "        chunks.append(chunk)\n",
    "print(\"Number of chunks: \", len(chunks))\n",
    "\n",
    "print(type(chunks[1]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Vector Database \n",
    "### Cache Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import hashlib \n",
    "from langchain.embeddings import HuggingFaceEmbeddings \n",
    "from langchain.vectorstores import FAISS \n",
    "\n",
    "\n",
    "def compute_document_hash(text_chunks: list, embedding_model: str) -> str:\n",
    "    \"\"\"\n",
    "    Compute a hash of the document content using the model name.\n",
    "    Args: \n",
    "        text_chunks: list of text chunks\n",
    "        embedding_model: name of the embedding model\n",
    "    Returns:\n",
    "        hash of the document content\n",
    "    \"\"\"\n",
    "\n",
    "    content = \"\".join(text_chunks) + embedding_model \n",
    "    return hashlib.sha256(content.encode()).hexdigest()[:16]\n",
    "\n",
    "\n",
    "def create_or_load_vector_store(chunks: list, embeddings: HuggingFaceEmbeddings, cache_dir: str) -> FAISS:\n",
    "    \"\"\" Retrieves a vector store from a list of text chunks using the given embeddings. \n",
    "    \n",
    "    Args: \n",
    "        chunks: list of text chunks\n",
    "        embeddings: embeddings model\n",
    "        cache_dir: directory to save the vector store\n",
    "    Returns:\n",
    "        FAISS object\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(cache_dir, exist_ok=True)\n",
    "\n",
    "\n",
    "    embedding_model_name = embeddings.model_name\n",
    "    current_hash = compute_document_hash(chunks, embedding_model_name)\n",
    "\n",
    "    # Check if cached index exists and contains a valid path \n",
    "    hash_file = os.path.join(cache_dir, \"content_hash.txt\")\n",
    "    index_file = os.path.join(cache_dir, \"index.faiss\")\n",
    "\n",
    "    if os.path.exists(index_file) and os.path.exists(hash_file):\n",
    "        with open(hash_file, \"r\") as f:\n",
    "            cached_hash = f.read().strip()\n",
    "\n",
    "            if current_hash == cached_hash:\n",
    "                print(\"Loading cached FAISS index for document retrieval\")\n",
    "                return FAISS.load_local(\n",
    "                    folder_path= cache_dir,\n",
    "                    embeddings=embeddings,\n",
    "                    allow_dangerous_deserialization=True\n",
    "                )\n",
    "            \n",
    "            else:\n",
    "                print(\"Cache invalidated: Documents and embeddings have changed.\")\n",
    "                print(\"Rebuilding vector store for updated documents...\")\n",
    "\n",
    "                # Delete existing index and hash file \n",
    "                for file in os.listdir(cache_dir):\n",
    "                    os.remove(os.path.join(cache_dir, file))\n",
    "    else:\n",
    "        print(\"No valid cache found. Creating new vector store...\")\n",
    "\n",
    "    \n",
    "    # Save the new index and hash file \n",
    "    print(f\"Creating a new vector store with {len(chunks)} document chunks...\")\n",
    "    vector_store = FAISS.from_texts(chunks, embedding = embeddings)\n",
    "\n",
    "    # Save the new index and hash\n",
    "    vector_store.save_local(cache_dir)\n",
    "    with open(hash_file, \"w\") as f:\n",
    "        f.write(current_hash)\n",
    "    \n",
    "    print(\"Vector store created and cached successfully!\")\n",
    "\n",
    "    return vector_store\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retriever Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/3n/nhd27m7j6plbm19rqj76xr_h0000gn/T/ipykernel_91151/1681077127.py:1: LangChainDeprecationWarning: The class `HuggingFaceEmbeddings` was deprecated in LangChain 0.2.2 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-huggingface package and should be used instead. To use it run `pip install -U :class:`~langchain-huggingface` and import as `from :class:`~langchain_huggingface import HuggingFaceEmbeddings``.\n",
      "  embeddings = HuggingFaceEmbeddings(\n",
      "/Users/kientran/Apps/OPT-RAG/rag-opt/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cache invalidated: Documents and embeddings have changed.\n",
      "Rebuilding vector store for updated documents...\n",
      "Creating a new vector store with 125 document chunks...\n",
      "Vector store created and cached successfully!\n",
      "[Document(id='1d9f3923-74db-464c-8073-16f94cf575df', metadata={}, page_content='Home>Working in the United States>Students and Exchange Visitors>Optional Practical Training (OPT)\\nfor F-1 Students\\nOptional Practical Training (OPT) for F-1\\nStudents\\n\\uf05aALERT: Please remember that photos submitted to USCIS must be unmounted and unretouched.\\nUnretouched means the photos must not be edited or digitally enhanced.\\xa0The submission of any\\nmounted or retouched images will delay the processing of your application and may prompt USCIS\\nto require you to visit an Application Support Center to verify your identity.\\nOptional practical training (OPT) is temporary employment that is directly related to an F-1 studentʼs major\\narea of study. Eligible students can apply to receive up to 12 months of OPT employment authorization before\\ncompleting their academic studies (pre-completion) and/or after completing their academic studies (post-\\ncompletion). However, all periods of pre-completion OPT will be deducted from the available period of post-\\ncompletion OPT.\\nTypes of OPT'), Document(id='219e2554-c375-4d76-b2ee-e8c699ea3cdc', metadata={}, page_content='Must apply within 60 days after your DSO enters the\\nrecommendation for OPT into your SEVIS record, and\\nMay apply up to 90 days before your current OPT\\nemployment authorization expires.\\n4/23/25, 4:47 PM Optional Practical Training (OPT) for F-1 Students | USCIS\\nhttps://www.uscis.gov/working-in-the-united-states/students-and-exchange-visitors/optional-practical-training-opt-for-f-1-students 3/5')]\n"
     ]
    }
   ],
   "source": [
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    model_kwargs = {\"device\": hardware}\n",
    ")\n",
    "\n",
    "vector_store = create_or_load_vector_store(chunks, embeddings, \"../vector_store\")\n",
    "\n",
    "query = \"What is OPT and if when should an international student apply for it?\"\n",
    "results = vector_store.search(query, k = 2, search_type = \"similarity\")\n",
    "print(results)\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    search_type=\"similarity\",\n",
    "    search_kwargs={\"k\":2}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download Qwen2.5b Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "# model_id = \"Qwen/Qwen2.5-1.5B-Instruct\"\n",
    "# local_model_path = \"../models/qwen2.5-1.5b\"\n",
    "\n",
    "# print(f\"Downloading {model_id} to {local_model_path}...\")\n",
    "# tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "# tokenizer.save_pretrained(local_model_path)\n",
    "\n",
    "# print(f\"Downloading model {model_id}...\")\n",
    "# model = AutoModelForCausalLM.from_pretrained(\n",
    "#     model_id,\n",
    "#     torch_dtype=\"auto\",\n",
    "# )\n",
    "# model.save_pretrained(local_model_path)\n",
    "\n",
    "# print(f\"Model {model_id} downloaded and saved to {local_model_path}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RAG Pipeline With OLLAMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\n",
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import pipeline\n",
    "\n",
    "def load_quantized_model(model_path=\"./models/qwen2.5-1.5b-instruct\", hardware=\"mps\"):\n",
    "    \"\"\"Load a quantized model optimized for inference performance.\"\"\"\n",
    "    \n",
    "    # Determine hardware and set up appropriate quantization\n",
    "    if hardware == \"cuda\":  # NVIDIA GPU\n",
    "        # 4-bit quantization for NVIDIA GPUs\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_4bit=True,\n",
    "            bnb_4bit_compute_dtype=torch.float16,\n",
    "            bnb_4bit_quant_type=\"nf4\",  # Normal Float 4 - better for language models\n",
    "            bnb_4bit_use_double_quant=True  # Further compression\n",
    "        )\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            device_map=\"auto\",\n",
    "            quantization_config=quantization_config\n",
    "        )\n",
    "        \n",
    "        # Compile model for faster execution on NVIDIA GPUs\n",
    "        if torch.__version__ >= \"2.0.0\":\n",
    "            model = torch.compile(model)\n",
    "            \n",
    "    elif hardware == \"mps\":  # Apple Silicon\n",
    "        # Apple Silicon doesn't support 4-bit quantization yet\n",
    "        # but we can optimize loading\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            device_map=\"auto\",\n",
    "            torch_dtype=torch.float16  # Use half precision\n",
    "        )\n",
    "        \n",
    "        \n",
    "    else:  # CPU\n",
    "        # 8-bit is more stable for CPU inference\n",
    "        quantization_config = BitsAndBytesConfig(\n",
    "            load_in_8bit=True\n",
    "        )\n",
    "        model = AutoModelForCausalLM.from_pretrained(\n",
    "            model_path,\n",
    "            device_map=\"auto\",\n",
    "            quantization_config=quantization_config\n",
    "        )\n",
    "    \n",
    "    # Load tokenizer\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_path)\n",
    "    \n",
    "    # Create optimized pipeline\n",
    "    pipe = pipeline(\n",
    "        \"text-generation\",\n",
    "        model=model,\n",
    "        tokenizer=tokenizer,\n",
    "        max_new_tokens=512,\n",
    "        repetition_penalty=1.1,\n",
    "        temperature=0.1,  # Low temperature for factual responses about visa information\n",
    "        do_sample=True\n",
    "    )\n",
    "    \n",
    "    # Wrap in LangChain\n",
    "    return HuggingFacePipeline(pipeline=pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prompt Engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'\n",
    "                    )\n",
    "logger = logging.getLogger(\"opt_rag\")\n",
    "\n",
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "visa_assistant_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "You are OPT-RAG, an expert assistant specializing in international student visa regulations and processes in the United States.\n",
    "\n",
    "## ROLE AND GUIDELINES\n",
    "- Provide accurate information based ONLY on official USCIS documents, university policies, and government regulations in the context provided\n",
    "- Focus specifically on visa-related issues: OPT applications, CPT authorization, study/work permits, and visa status questions\n",
    "- NEVER fabricate information or provide speculative advice on visa matters\n",
    "- If information is not available in the context, clearly state this limitation\n",
    "- Always indicate the source of information in your responses\n",
    "- Avoid legal advice; clarify when questions require consultation with immigration attorneys\n",
    "\n",
    "## CONTEXT\n",
    "{context}\n",
    "\n",
    "## USER INFORMATION\n",
    "Student status: International student in the United States\n",
    "Primary concern: Visa and immigration matters\n",
    "\n",
    "## RESPONSE FORMAT\n",
    "- Begin with a direct answer to the question\n",
    "- Provide specific, relevant details from official sources\n",
    "- Include citation to specific documents/policies when available\n",
    "- Highlight important deadlines or requirements\n",
    "- If applicable, mention next steps the student should take\n",
    "- End with a disclaimer that this information is not legal advice\n",
    "\n",
    "## QUESTION\n",
    "{input}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "def create_rag_chain(llm, vector_store):\n",
    "    \"\"\"Create a RAG chain for the international student visa assistant.\"\"\"\n",
    "    \n",
    "    # Create retriever from vector store\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 5}  # Retrieve top 5 most relevant documents\n",
    "    )\n",
    "    \n",
    "    # Create combine documents chain with our enhanced prompt\n",
    "    combine_docs_chain = create_stuff_documents_chain(\n",
    "        llm=llm,\n",
    "        prompt=visa_assistant_prompt\n",
    "    )\n",
    "    \n",
    "    # Create and return the retrieval chain\n",
    "    return create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=combine_docs_chain\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_streaming_rag_chain(llm, vector_store, verbose=True):\n",
    "    \"\"\"Create a RAG chain with streaming and debug capabilities.\n",
    "    \n",
    "    Args:\n",
    "        llm: Language model for generation\n",
    "        vector_store: Vector store for retrieval\n",
    "        verbose: Whether to print debug information\n",
    "        \n",
    "    Returns:\n",
    "        A RAG chain with streaming and debugging\n",
    "    \"\"\"\n",
    "\n",
    "    from langchain.chains import create_retrieval_chain\n",
    "    from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "    from langchain_core.prompts import ChatPromptTemplate\n",
    "    from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "    from langchain.callbacks.manager import CallbackManager\n",
    "    \n",
    "    # Set up callback manager for streaming and logging\n",
    "    callbacks = []\n",
    "    if verbose:\n",
    "        callbacks.append(StreamingStdOutCallbackHandler())\n",
    "    \n",
    "    callback_manager = CallbackManager(callbacks)\n",
    "\n",
    "    # Create prompt with debugging flags\n",
    "    \n",
    "    # Create retriever with debug output\n",
    "    retriever = vector_store.as_retriever(\n",
    "        search_type=\"similarity\",\n",
    "        search_kwargs={\"k\": 3}\n",
    "    )\n",
    "    \n",
    "    # Create chain with callbacks for streaming\n",
    "    combine_docs_chain = create_stuff_documents_chain(\n",
    "        llm=llm.with_config({\"callbacks\": callbacks}),  # Add streaming to LLM\n",
    "        prompt=visa_assistant_prompt\n",
    "    )\n",
    "\n",
    "    # Create and return retrieval chain\n",
    "    return create_retrieval_chain(\n",
    "        retriever=retriever,\n",
    "        combine_docs_chain=combine_docs_chain\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-26 17:05:57,476 - httpx - INFO - HTTP Request: POST http://127.0.0.1:11434/api/generate \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 5.237255811691284 seconds\n",
      "The most recent date on which USCIS has specified as being acceptable for filing an OPT application is March 15th, 2023. This is based on guidance provided by USCIS. As of that date, applications must be received through the mail or electronically.\n",
      "\n",
      "### Important Notes:\n",
      "- Ensure all fees are paid.\n",
      "- Check your immigration status and ensure you meet any residency requirements within the US.\n",
      "- Make sure to submit all required documents in a timely manner for the application to be processed correctly.\n",
      "\n",
      "If you need further assistance with filing, please contact the International Student Office at [email].\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "user_query = \"What is the latest you can file your OPT application?\"\n",
    "\n",
    "rag_chain = create_rag_chain(llm, vector_store)\n",
    "\n",
    "start_time = time.time()\n",
    "\n",
    "response = rag_chain.invoke({\"input\": user_query})\n",
    "\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Time taken: {end_time - start_time} seconds\")\n",
    "\n",
    "print(response[\"answer\"])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'dict'>\n",
      "dict_keys(['input', 'context', 'answer'])\n"
     ]
    }
   ],
   "source": [
    "print(type(response))\n",
    "print(response.keys())\n",
    "\n",
    "with open(\"output.txt\", \"w\") as file:\n",
    "    file.write(response['answer'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-opt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
